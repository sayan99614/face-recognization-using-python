{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are you verified with our face recognization system\n",
      "plz enter yes or no\n",
      "yes\n",
      "230 237 228 228\n",
      "222 237 228 228\n",
      "222 235 228 228\n",
      "228 236 228 228\n",
      "223 236 228 228\n",
      "224 238 228 228\n",
      "220 236 228 228\n",
      "186 233 228 228\n",
      "188 232 228 228\n",
      "188 245 228 228\n",
      "214 242 228 228\n",
      "216 245 228 228\n",
      "211 245 228 228\n",
      "216 245 228 228\n",
      "216 239 228 228\n",
      "198 260 152 152\n",
      "2\n",
      "suman\n",
      "247 272 152 152\n",
      "2\n",
      "suman\n",
      "257 271 152 152\n",
      "2\n",
      "suman\n",
      "271 234 152 152\n",
      "2\n",
      "suman\n",
      "273 232 152 152\n",
      "2\n",
      "suman\n",
      "266 232 152 152\n",
      "2\n",
      "suman\n",
      "266 237 152 152\n",
      "2\n",
      "suman\n",
      "261 236 152 152\n",
      "2\n",
      "suman\n",
      "264 232 152 152\n",
      "2\n",
      "suman\n",
      "267 233 152 152\n",
      "2\n",
      "suman\n",
      "266 232 152 152\n",
      "2\n",
      "suman\n",
      "266 235 152 152\n",
      "2\n",
      "suman\n",
      "263 235 152 152\n",
      "2\n",
      "suman\n",
      "263 236 152 152\n",
      "2\n",
      "suman\n",
      "264 235 152 152\n",
      "2\n",
      "suman\n",
      "264 235 152 152\n",
      "2\n",
      "suman\n",
      "222 203 228 228\n",
      "2\n",
      "suman\n",
      "259 229 152 152\n",
      "2\n",
      "suman\n",
      "243 224 152 152\n",
      "2\n",
      "suman\n",
      "23 222 228 228\n",
      "2\n",
      "suman\n"
     ]
    }
   ],
   "source": [
    "print(\"are you verified with our face recognization system\")\n",
    "n=input(\"plz enter yes or no\\n\")\n",
    "li=[\"yes\",\"no\"]\n",
    "if(n==li[0]):\n",
    "    face_cascade = cv2.CascadeClassifier('/home/dheeman/python/fcae recog/opencv-files/haarcascade_frontalface_alt.xml')\n",
    "    recognizer=cv2.face.createLBPHFaceRecognizer()\n",
    "    recognizer.load('/home/dheeman/python/fcae recog/trainner.yml')\n",
    "    labels={\"person_name\":1}\n",
    "    with open(\"labels.pickle\",'rb') as f:\n",
    "        og_labels=pickle.load(f)\n",
    "        labels={v:k for k,v in og_labels.items()}\n",
    "    cap=cv2.VideoCapture(0)\n",
    "    while(True):\n",
    "        #capture frames \n",
    "        ret,frame=cap.read()\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces=face_cascade.detectMultiScale(gray,scaleFactor=1.5, minNeighbors=5)\n",
    "        #recognize\n",
    "        for (x,y,w,h) in faces:\n",
    "            print(x,y,w,h)\n",
    "            roi_gray=gray[y:y+h,x:x+w]\n",
    "            roi_color=frame[y:y+h,x:x+w]\n",
    "            id_,conf=recognizer.predict(roi_gray)\n",
    "            if conf>=45:\n",
    "                print(id_)\n",
    "                print(labels[id_])\n",
    "                font=cv2.FONT_HERSHEY_COMPLEX\n",
    "                name=labels[id_]\n",
    "                color=(255,255,255)\n",
    "                stroke=2\n",
    "                cv2.putText(frame,name,(x,y),font,1,color,stroke,cv2.LINE_AA)\n",
    "            img_item=\"4.png\"\n",
    "            cv2.imwrite(img_item,roi_color)\n",
    "            color=(255,0,0)\n",
    "            stroke=2\n",
    "            width=x+w\n",
    "            height=y+h\n",
    "            cv2.rectangle(frame, (x,y), (width,height),color, stroke)\n",
    "        #display the resulting frames\n",
    "        cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "if(n==li[1]):\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    print(\"                WELCOME TO OUR FACE RECOGNIZATION SYSTEM                  \")\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    directory = input(\"enter your name\\n\") \n",
    "    parent_dir = \"/home/dheeman/python/fcae recog/images/\"  \n",
    "    path = os.path.join(parent_dir, directory) \n",
    "    try: \n",
    "        os.makedirs(path, exist_ok = True) \n",
    "    except OSError as error: \n",
    "        print(\"Directory '%s' can not be created\" % directory) \n",
    "    s_path=\"/home/dheeman/python/fcae recog/images/{}/\".format(directory)\n",
    "    camera = cv2.VideoCapture(0)\n",
    "    for i in range(10):\n",
    "        return_value, image = camera.read()\n",
    "        cv2.imwrite(os.path.join(s_path,'opencv'+str(i)+'.png'),image)\n",
    "    del(camera)\n",
    "    # in this part the camera will capture 10 photos, according to the name entered by the user it create a directory of named person and save the images in that directory\n",
    "    #this part have not done yet\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shubham /home/dheeman/python/fcae recog/images/shubham/shubham.jpg\n",
      "{'shubham': 0}\n",
      "maa /home/dheeman/python/fcae recog/images/maa/opencv2.png\n",
      "{'shubham': 0, 'maa': 1}\n",
      "maa /home/dheeman/python/fcae recog/images/maa/opencv8.png\n",
      "{'shubham': 0, 'maa': 1}\n",
      "maa /home/dheeman/python/fcae recog/images/maa/opencv7.png\n",
      "{'shubham': 0, 'maa': 1}\n",
      "maa /home/dheeman/python/fcae recog/images/maa/opencv1.png\n",
      "{'shubham': 0, 'maa': 1}\n",
      "maa /home/dheeman/python/fcae recog/images/maa/opencv0.png\n",
      "{'shubham': 0, 'maa': 1}\n",
      "maa /home/dheeman/python/fcae recog/images/maa/opencv4.png\n",
      "{'shubham': 0, 'maa': 1}\n",
      "maa /home/dheeman/python/fcae recog/images/maa/opencv3.png\n",
      "{'shubham': 0, 'maa': 1}\n",
      "maa /home/dheeman/python/fcae recog/images/maa/opencv6.png\n",
      "{'shubham': 0, 'maa': 1}\n",
      "maa /home/dheeman/python/fcae recog/images/maa/opencv9.png\n",
      "{'shubham': 0, 'maa': 1}\n",
      "maa /home/dheeman/python/fcae recog/images/maa/opencv5.png\n",
      "{'shubham': 0, 'maa': 1}\n",
      "suman /home/dheeman/python/fcae recog/images/suman/opencv2.png\n",
      "{'shubham': 0, 'maa': 1, 'suman': 2}\n",
      "suman /home/dheeman/python/fcae recog/images/suman/opencv8.png\n",
      "{'shubham': 0, 'maa': 1, 'suman': 2}\n",
      "suman /home/dheeman/python/fcae recog/images/suman/opencv7.png\n",
      "{'shubham': 0, 'maa': 1, 'suman': 2}\n",
      "suman /home/dheeman/python/fcae recog/images/suman/opencv1.png\n",
      "{'shubham': 0, 'maa': 1, 'suman': 2}\n",
      "suman /home/dheeman/python/fcae recog/images/suman/opencv0.png\n",
      "{'shubham': 0, 'maa': 1, 'suman': 2}\n",
      "suman /home/dheeman/python/fcae recog/images/suman/opencv4.png\n",
      "{'shubham': 0, 'maa': 1, 'suman': 2}\n",
      "suman /home/dheeman/python/fcae recog/images/suman/opencv3.png\n",
      "{'shubham': 0, 'maa': 1, 'suman': 2}\n",
      "suman /home/dheeman/python/fcae recog/images/suman/opencv6.png\n",
      "{'shubham': 0, 'maa': 1, 'suman': 2}\n",
      "suman /home/dheeman/python/fcae recog/images/suman/opencv9.png\n",
      "{'shubham': 0, 'maa': 1, 'suman': 2}\n",
      "suman /home/dheeman/python/fcae recog/images/suman/opencv5.png\n",
      "{'shubham': 0, 'maa': 1, 'suman': 2}\n",
      "sayan /home/dheeman/python/fcae recog/images/sayan/opencv2.png\n",
      "{'shubham': 0, 'maa': 1, 'suman': 2, 'sayan': 3}\n",
      "sayan /home/dheeman/python/fcae recog/images/sayan/opencv8.png\n",
      "{'shubham': 0, 'maa': 1, 'suman': 2, 'sayan': 3}\n",
      "sayan /home/dheeman/python/fcae recog/images/sayan/opencv7.png\n",
      "{'shubham': 0, 'maa': 1, 'suman': 2, 'sayan': 3}\n",
      "sayan /home/dheeman/python/fcae recog/images/sayan/opencv1.png\n",
      "{'shubham': 0, 'maa': 1, 'suman': 2, 'sayan': 3}\n",
      "sayan /home/dheeman/python/fcae recog/images/sayan/opencv0.png\n",
      "{'shubham': 0, 'maa': 1, 'suman': 2, 'sayan': 3}\n",
      "sayan /home/dheeman/python/fcae recog/images/sayan/opencv4.png\n",
      "{'shubham': 0, 'maa': 1, 'suman': 2, 'sayan': 3}\n",
      "sayan /home/dheeman/python/fcae recog/images/sayan/opencv3.png\n",
      "{'shubham': 0, 'maa': 1, 'suman': 2, 'sayan': 3}\n",
      "sayan /home/dheeman/python/fcae recog/images/sayan/opencv6.png\n",
      "{'shubham': 0, 'maa': 1, 'suman': 2, 'sayan': 3}\n",
      "sayan /home/dheeman/python/fcae recog/images/sayan/opencv9.png\n",
      "{'shubham': 0, 'maa': 1, 'suman': 2, 'sayan': 3}\n",
      "sayan /home/dheeman/python/fcae recog/images/sayan/opencv5.png\n",
      "{'shubham': 0, 'maa': 1, 'suman': 2, 'sayan': 3}\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pickle\n",
    "face_cascade = cv2.CascadeClassifier('/home/dheeman/python/fcae recog/opencv-files/haarcascade_frontalface_alt.xml')\n",
    "base_dir=os.path.dirname(os.path.abspath('__file__'))\n",
    "image_dir=os.path.join(base_dir,\"images\")\n",
    "face_cascade = cv2.CascadeClassifier('/home/dheeman/python/fcae recog/opencv-files/haarcascade_frontalface_alt.xml')\n",
    "current_id=0\n",
    "label_ids={}\n",
    "recognizer=cv2.face.createLBPHFaceRecognizer()\n",
    "y_labels=[]\n",
    "x_train=[]\n",
    "for root,dirs,files in os.walk(image_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\"png\") or file.endswith(\"jpg\"):\n",
    "            path=os.path.join(root,file)\n",
    "            label=os.path.basename(root).replace(\" \",\"-\").lower()\n",
    "            print(label,path)\n",
    "            if not label in label_ids:\n",
    "                label_ids[label]=current_id\n",
    "                current_id+=1\n",
    "            id_=label_ids[label]\n",
    "            print(label_ids)\n",
    "            pil_image=Image.open(path).convert(\"L\")\n",
    "            size=(550,550)\n",
    "            final_image=pil_image.resize(size,Image.ANTIALIAS)\n",
    "            image_array=np.array(final_image)\n",
    "            #print(image_array)\n",
    "            faces = face_cascade.detectMultiScale(image_array, scaleFactor=1.5, minNeighbors=5)\n",
    "            \n",
    "            for (x,y,w,h) in faces:\n",
    "                roi=image_array[y:y+h,x:x+w]\n",
    "                x_train.append(roi)\n",
    "                y_labels.append(id_)\n",
    "               \n",
    "\n",
    "with open(\"labels.pickle\",'wb') as f:\n",
    "    pickle.dump(label_ids,f)\n",
    "recognizer.train(x_train,np.array(y_labels))\n",
    "recognizer.save(\"trainner.yml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
